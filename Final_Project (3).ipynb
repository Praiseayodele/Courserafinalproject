{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center\">\n",
    "    <a href=\"https://skills.network/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMSkillsNetworkBD0231ENCoursera2789-2023-01-01\">\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\">\n",
    "    </a>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Project - Build an ML Pipeline for Airfoil noise prediction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimated time needed: **90** minutes\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are a data engineer at an aeronautics consulting company. Your company prides itself in being able to efficiently design airfoils for use in planes and sports cars. Data scientists in your office need to work with different algorithms and data in different formats. While they are good at Machine Learning, they count on you to be able to do ETL jobs and build ML pipelines. In this project you will use the modified version of the NASA Airfoil Self Noise dataset. You will clean this dataset, by dropping the duplicate rows, and removing the rows with null values. You will create an ML pipe line to create a model that will predict the SoundLevel based on all the other columns. You will evaluate the model and towards the end you will persist the model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "In this 4 part assignment you will:\n",
    "\n",
    "- Part 1 Perform ETL activity\n",
    "  - Load a csv dataset\n",
    "  - Remove duplicates if any\n",
    "  - Drop rows with null values if any\n",
    "  - Make transformations\n",
    "  - Store the cleaned data in parquet format\n",
    "- Part 2 Create a  Machine Learning Pipeline\n",
    "  - Create a machine learning pipeline for prediction\n",
    "- Part 3 Evaluate the Model\n",
    "  - Evaluate the model using relevant metrics\n",
    "- Part 4 Persist the Model \n",
    "  - Save the model for future production use\n",
    "  - Load and verify the stored model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets\n",
    "\n",
    "In this lab you will be using dataset(s):\n",
    "\n",
    " - The original dataset can be found here NASA airfoil self noise dataset. https://archive.ics.uci.edu/dataset/291/airfoil+self+noise\n",
    " \n",
    " - This dataset is licensed under a Creative Commons Attribution 4.0 International (CC BY 4.0) license.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diagram of an airfoil. - For informational purpose\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Airfoil with flow](https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-BD0231EN-Coursera/images/Airfoil_with_flow.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diagram showing the Angle of attack. - For informational purpose\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Airfoil angle of attack](https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-BD0231EN-Coursera/images/Airfoil_angle_of_attack.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before you Start\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you start attempting this project it is highly recommended that you finish the practice project.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this lab, we will be using the following libraries:\n",
    "\n",
    "*   [`PySpark`](https://spark.apache.org/docs/latest/api/python/index.html?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMSkillsNetworkBD0231ENCoursera2789-2023-01-01) for connecting to the Spark Cluster\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing Required Libraries\n",
    "\n",
    "Spark Cluster is pre-installed in the Skills Network Labs environment. However, you need libraries like pyspark and findspark to\n",
    " connect to this cluster.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following required libraries are __not__ pre-installed in the Skills Network Labs environment. __You will need to run the following cell__ to install them:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install pyspark==3.1.2 -q\n",
    "!pip install findspark -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Required Libraries\n",
    "\n",
    "_We recommend you import all required libraries in one place (here):_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# You can also use this section to suppress warnings generated by your code:\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# FindSpark simplifies the process of using Apache Spark with Python\n",
    "\n",
    "import findspark\n",
    "findspark.init()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 - Perform ETL activity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1 - Import required libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.pipeline import PipelineModel\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2 - Create a spark session\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "spark = SparkSession.builder.appName(\"Final_Project\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3 - Load the csv file into a dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the data file.\n",
    "\n",
    "NOTE : Please ensure you use the dataset below and not the original dataset mentioned above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!wget https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-BD0231EN-Coursera/datasets/NASA_airfoil_noise_raw.csv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset into the spark dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_path = \"NASA_airfoil_noise_raw.csv\"\n",
    "\n",
    "df = spark.read.csv(file_path, header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4 - Print top 5 rows of the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------+-----------+------------------+-----------------------+----------+\n",
      "|Frequency|AngleOfAttack|ChordLength|FreeStreamVelocity|SuctionSideDisplacement|SoundLevel|\n",
      "+---------+-------------+-----------+------------------+-----------------------+----------+\n",
      "|      800|          0.0|     0.3048|              71.3|             0.00266337|   126.201|\n",
      "|     1000|          0.0|     0.3048|              71.3|             0.00266337|   125.201|\n",
      "|     1250|          0.0|     0.3048|              71.3|             0.00266337|   125.951|\n",
      "|     1600|          0.0|     0.3048|              71.3|             0.00266337|   127.591|\n",
      "|     2000|          0.0|     0.3048|              71.3|             0.00266337|   127.461|\n",
      "+---------+-------------+-----------+------------------+-----------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#your code goes here\n",
    "# Printing top 5 rows of the dataset\n",
    "df.show(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6 - Print the total number of rows in the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of rows in the dataset: 1522\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "total_rows = df.count()\n",
    "print(\"Total number of rows in the dataset:\", total_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 7 - Drop all the duplicate rows from the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 27:============================================>         (164 + 8) / 200]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of rows after dropping duplicates: 1503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_no_duplicates = df.dropDuplicates()\n",
    "total_rows_no_duplicates = df_no_duplicates.count()\n",
    "print(\"Total number of rows after dropping duplicates:\", total_rows_no_duplicates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Task 8 - Print the total number of rows in the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of rows after dropping duplicates: 1503\n"
     ]
    }
   ],
   "source": [
    "total_rows_no_duplicates = df_no_duplicates.count()\n",
    "print(\"Total number of rows after dropping duplicates:\", total_rows_no_duplicates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 9 - Drop all the rows that contain null values from the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 33:==============================================>      (174 + 10) / 200]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of rows after dropping rows with null values: 1499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Drop all rows that contain null values from the dataset\n",
    "df_no_null = df_no_duplicates.dropna()\n",
    "\n",
    "# Print the total number of rows after dropping rows with null values\n",
    "total_rows_no_null = df_no_null.count()\n",
    "print(\"Total number of rows after dropping rows with null values:\", total_rows_no_null)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 10 - Print the total number of rows in the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 24:=================================================>    (183 + 8) / 200]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of rows in the dataset after dropping rows with null values: 1499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Print the total number of rows in the dataset after dropping rows with null values\n",
    "total_rows_no_null = df_no_null.count()\n",
    "print(\"Total number of rows in the dataset after dropping rows with null values:\", total_rows_no_null)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 11 - Rename the column \"SoundLevel\" to \"SoundLevelDecibels\"Drop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Frequency: integer (nullable = true)\n",
      " |-- AngleOfAttack: double (nullable = true)\n",
      " |-- ChordLength: double (nullable = true)\n",
      " |-- FreeStreamVelocity: double (nullable = true)\n",
      " |-- SuctionSideDisplacement: double (nullable = true)\n",
      " |-- SoundLevelDecibels: double (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Frequency',\n",
       " 'AngleOfAttack',\n",
       " 'ChordLength',\n",
       " 'FreeStreamVelocity',\n",
       " 'SuctionSideDisplacement',\n",
       " 'SoundLevelDecibels']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rename the column \"SoundLevel\" to \"SoundLevelDecibels\" and drop the original column\n",
    "df_renamed = df.withColumnRenamed(\"SoundLevel\", \"SoundLevelDecibels\").drop(\"SoundLevel\")\n",
    "\n",
    "# Printing the schema to verify column renaming and dropping\n",
    "df_renamed.printSchema()\n",
    "df_renamed.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 12 - Save the dataframe in parquet formant, name the file as \"NASA_airfoil_noise_cleaned.parquet\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_renamed.write.parquet(\"new_path/NASA_airfoil_noise_cleaned_v6.parquet\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 1 - Evaluation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Run the code cell below.<br>\n",
    "Use the answers here to answer the final evaluation quiz in the next section.<br>\n",
    "If the code throws up any errors, go back and review the code you have written.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "rowcount1 = df_renamed.count() # Total rows in the original DataFrame\n",
    "rowcount2 = df_renamed.dropDuplicates().count() # Total rows after dropping duplicate rows\n",
    "rowcount3 = df_renamed.dropDuplicates().na.drop().count() # Total rows after dropping duplicate rows and rows with null values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part - 2 Create a  Machine Learning Pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1 - Load data from \"NASA_airfoil_noise_cleaned.parquet\" into a dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load data from Parquet file into a DataFrame\n",
    "df = spark.read.parquet(\"new_path/NASA_airfoil_noise_cleaned_v6.parquet\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2 - Print the total number of rows in the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of rows: 1522\n"
     ]
    }
   ],
   "source": [
    "# Print the total number of rows in the dataset\n",
    "print(\"Total number of rows:\", df.count())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3 - Define the VectorAssembler pipeline stage\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stage 1 - Assemble the input columns into a single column \"features\". Use all the columns except SoundLevelDecibels as input features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "# Define the input columns (excluding SoundLevelDecibels)\n",
    "input_cols = [col for col in df.columns if col != \"SoundLevelDecibels\"]\n",
    "\n",
    "# Create a VectorAssembler object with handleInvalid=\"skip\"\n",
    "assembler = VectorAssembler(inputCols=input_cols, outputCol=\"features\", handleInvalid=\"skip\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4 - Define the StandardScaler pipeline stage\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stage 2 - Scale the \"features\" using standard scaler and store in \"scaledFeatures\" column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StandardScaler\n",
    "\n",
    "# Define the StandardScaler object\n",
    "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\", withStd=True, withMean=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5 - Define the StandardScaler pipeline stage\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stage 3 - Create a LinearRegression stage to predict \"SoundLevelDecibels\"\n",
    "\n",
    "**Note:You need to use the scaledfeatures retreived in the previous step.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "# Create a LinearRegression object\n",
    "linear_regression = LinearRegression(featuresCol=\"scaledFeatures\", labelCol=\"SoundLevelDecibels\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6 - Build the pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a pipeline using the above three stages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# Define the stages of the pipeline\n",
    "stages = [assembler, scaler, linear_regression]\n",
    "\n",
    "# Create a Pipeline object\n",
    "pipeline = Pipeline(stages=stages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 7 - Split the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets (70% training, 30% testing)\n",
    "train_data, test_data = df.randomSplit([0.7, 0.3], seed=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 8 - Fit the pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/16 18:58:36 WARN util.Instrumentation: [5214cb73] regParam is zero, which might cause numerical instability and overfitting.\n",
      "24/04/16 18:58:37 WARN netlib.BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS\n",
      "24/04/16 18:58:37 WARN netlib.BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS\n",
      "24/04/16 18:58:37 WARN netlib.LAPACK: Failed to load implementation from: com.github.fommil.netlib.NativeSystemLAPACK\n",
      "24/04/16 18:58:37 WARN netlib.LAPACK: Failed to load implementation from: com.github.fommil.netlib.NativeRefLAPACK\n"
     ]
    }
   ],
   "source": [
    "# Fit the pipeline to the training data\n",
    "pipeline_model = pipeline.fit(train_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 2 - Evaluation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Run the code cell below.<br>\n",
    "Use the answers here to answer the final evaluation quiz in the next section.<br>\n",
    "If the code throws up any errors, go back and review the code you have written.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/16 18:58:46 WARN util.Instrumentation: [804e2ceb] regParam is zero, which might cause numerical instability and overfitting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 2 - Evaluation\n",
      "Total rows = 1522\n",
      "Pipeline Stage 1 = VectorAssembler\n",
      "Pipeline Stage 2 = StandardScaler\n",
      "Pipeline Stage 3 = LinearRegression\n",
      "Label column = SoundLevelDecibels\n"
     ]
    }
   ],
   "source": [
    "# Fit the pipeline to the training data\n",
    "pipeline_model = pipeline.fit(train_data)\n",
    "\n",
    "# Calculate the total number of rows in the DataFrame\n",
    "rowcount4 = df.count()\n",
    "\n",
    "print(\"Part 2 - Evaluation\")\n",
    "print(\"Total rows =\", rowcount4)\n",
    "\n",
    "# Get the stages of the pipeline\n",
    "ps = [str(x).split(\"_\")[0] for x in pipeline_model.stages]\n",
    "\n",
    "print(\"Pipeline Stage 1 =\", ps[0])\n",
    "print(\"Pipeline Stage 2 =\", ps[1])\n",
    "print(\"Pipeline Stage 3 =\", ps[2])\n",
    "\n",
    "# Print the label column of the linear regression model\n",
    "print(\"Label column =\", linear_regression.getLabelCol())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3 - Evaluate the Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1 - Predict using the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Predict using the fitted pipeline model on the test data\n",
    "predictions = pipeline_model.transform(test_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2 - Print the MSE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(predictions.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE) on test data = 24.08531562389462\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# Define the evaluator\n",
    "evaluator = RegressionEvaluator(labelCol=\"SoundLevelDecibels\", predictionCol=\"prediction\", metricName=\"mse\")\n",
    "\n",
    "# Calculate the MSE\n",
    "mse = evaluator.evaluate(predictions)\n",
    "\n",
    "# Print the MSE\n",
    "print(\"Mean Squared Error (MSE) on test data =\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 24.08531562389462\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# Calculate the MSE using RegressionEvaluator\n",
    "evaluator_mse = RegressionEvaluator(predictionCol=\"prediction\", labelCol=\"SoundLevelDecibels\", metricName=\"mse\")\n",
    "mse = evaluator_mse.evaluate(predictions)\n",
    "print(\"Mean Squared Error (MSE):\", mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3 - Print the MAE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE) on test data = 3.8171443447680273\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# Define the evaluator\n",
    "evaluator = RegressionEvaluator(labelCol=\"SoundLevelDecibels\", predictionCol=\"prediction\", metricName=\"mae\")\n",
    "\n",
    "# Calculate the MAE\n",
    "mae = evaluator.evaluate(predictions)\n",
    "\n",
    "# Print the MAE\n",
    "print(\"Mean Absolute Error (MAE) on test data =\", mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# Create an evaluator for regression metrics\n",
    "evaluator = RegressionEvaluator(labelCol=\"SoundLevelDecibels\", predictionCol=\"prediction\", metricName=\"mae\")\n",
    "\n",
    "# Calculate the MAE\n",
    "mae = evaluator.evaluate(predictions)\n",
    "\n",
    "# Print the MAE\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4 - Print the R-Squared(R2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared (R2) on test data = 0.4993866299512747\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# Define the evaluator\n",
    "evaluator = RegressionEvaluator(labelCol=\"SoundLevelDecibels\", predictionCol=\"prediction\", metricName=\"r2\")\n",
    "\n",
    "# Calculate the R2 score\n",
    "r2 = evaluator.evaluate(predictions)\n",
    "\n",
    "# Print the R2 score\n",
    "print(\"R-squared (R2) on test data =\", r2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 3 - Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get the intercept of the linear regression model\n",
    "intercept = loaded_model_lr.intercept\n",
    "\n",
    "# Print the intercept\n",
    "print(\"Intercept =\", round(intercept, 4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 3 - Evaluation\n",
      "Mean Squared Error = 24.09\n",
      "Mean Absolute Error = 3.82\n",
      "R Squared = 0.5\n",
      "Intercept = 124.64\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# Calculate the MSE\n",
    "evaluator_mse = RegressionEvaluator(predictionCol=\"prediction\", labelCol=\"SoundLevelDecibels\", metricName=\"mse\")\n",
    "mse = evaluator_mse.evaluate(predictions)\n",
    "\n",
    "# Calculate the MAE\n",
    "evaluator_mae = RegressionEvaluator(predictionCol=\"prediction\", labelCol=\"SoundLevelDecibels\", metricName=\"mae\")\n",
    "mae = evaluator_mae.evaluate(predictions)\n",
    "\n",
    "# Calculate the R2\n",
    "evaluator_r2 = RegressionEvaluator(predictionCol=\"prediction\", labelCol=\"SoundLevelDecibels\", metricName=\"r2\")\n",
    "r2 = evaluator_r2.evaluate(predictions)\n",
    "\n",
    "# Get the linear regression model\n",
    "lrModel = pipeline_model.stages[-1]\n",
    "\n",
    "# Print the evaluation metrics and intercept\n",
    "print(\"Part 3 - Evaluation\")\n",
    "print(\"Mean Squared Error =\", round(mse, 2))\n",
    "print(\"Mean Absolute Error =\", round(mae, 2))\n",
    "print(\"R Squared =\", round(r2, 2))\n",
    "print(\"Intercept =\", round(lrModel.intercept, 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 3 - Evaluation\n",
      "Mean Squared Error = 24.09\n",
      "Mean Absolute Error = 3.82\n",
      "R Squared = 0.5\n",
      "Intercept = 124.64\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# Calculate the MSE\n",
    "evaluator_mse = RegressionEvaluator(predictionCol=\"prediction\", labelCol=\"SoundLevelDecibels\", metricName=\"mse\")\n",
    "mse = evaluator_mse.evaluate(predictions)\n",
    "\n",
    "# Calculate the MAE\n",
    "evaluator_mae = RegressionEvaluator(predictionCol=\"prediction\", labelCol=\"SoundLevelDecibels\", metricName=\"mae\")\n",
    "mae = evaluator_mae.evaluate(predictions)\n",
    "\n",
    "# Calculate the R2\n",
    "evaluator_r2 = RegressionEvaluator(predictionCol=\"prediction\", labelCol=\"SoundLevelDecibels\", metricName=\"r2\")\n",
    "r2 = evaluator_r2.evaluate(predictions)\n",
    "\n",
    "# Get the linear regression model\n",
    "lrModel = pipeline_model.stages[-1]\n",
    "\n",
    "# Print the evaluation metrics and intercept\n",
    "print(\"Part 3 - Evaluation\")\n",
    "print(\"Mean Squared Error =\", round(mse, 2))\n",
    "print(\"Mean Absolute Error =\", round(mae, 2))\n",
    "print(\"R Squared =\", round(r2, 2))\n",
    "print(\"Intercept =\", round(lrModel.intercept, 2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Run the code cell below.<br>\n",
    "Use the answers here to answer the final evaluation quiz in the next section.<br>\n",
    "If the code throws up any errors, go back and review the code you have written.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Part 3 - Evaluation\")\n",
    "print(\"Mean Squared Error = \", round(mse, 2))\n",
    "print(\"Mean Absolute Error = \", round(mae, 2))\n",
    "print(\"R Squared = \", round(r2, 2))\n",
    "\n",
    "lrModel = pipeline_model.stages[-1]\n",
    "\n",
    "print(\"Intercept = \", round(lrModel.intercept, 2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4 - Persist the Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1 - Save the model to the path \"Final_Project\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "pipeline_model.write().save(\"Final_Project2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2 - Load the model from the path \"Final_Project\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.ml import PipelineModel\n",
    "\n",
    "# Load the model from the specified path\n",
    "loaded_model = PipelineModel.load(\"Final_Project2\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3 - Make predictions using the loaded model on the testdata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Make predictions using the loaded model on the test data\n",
    "loaded_predictions = loaded_model.transform(test_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4 - Show the predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Show the predictions made by the loaded model\n",
    "loaded_predictions.select(\"SoundLevelDecibels\", \"prediction\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 4 - Evaluation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Run the code cell below.<br>\n",
    "Use the answers here to answer the final evaluation quiz in the next section.<br>\n",
    "If the code throws up any errors, go back and review the code you have written.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Part 4 - Evaluation\")\n",
    "\n",
    "# Get the final linear regression model from the loaded pipeline model\n",
    "loaded_model_lr = loaded_model.stages[-1]\n",
    "\n",
    "# Get the total number of stages in the pipeline\n",
    "total_stages = len(loaded_model.stages)\n",
    "print(\"Number of stages in the pipeline =\", total_stages)\n",
    "\n",
    "# Get the input columns used in the VectorAssembler stage\n",
    "input_columns = loaded_model.stages[0].getInputCols()\n",
    "\n",
    "# Get the coefficients of the features\n",
    "coefficients = loaded_model_lr.coefficients\n",
    "\n",
    "# Print the coefficients for each feature\n",
    "for i, j in zip(input_columns, coefficients):\n",
    "    print(f\"Coefficient for {i} is {round(j, 4)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Part 4 - Evaluation\")\n",
    "\n",
    "loadedmodel = loaded_model.stages[-1]\n",
    "totalstages = len(loaded_model.stages)\n",
    "inputcolumns = loaded_model.stages[0].getInputCols()\n",
    "\n",
    "print(\"Number of stages in the pipeline = \", totalstages)\n",
    "for i,j in zip(inputcolumns, loadedmodel.coefficients):\n",
    "    print(f\"Coefficient for {i} is {round(j,4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop Spark Session\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Ramesh Sannareddy](https://www.linkedin.com/in/rsannareddy/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMBD0231ENSkillsNetwork866-2023-01-01)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Contributors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change Log\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Date (YYYY-MM-DD)|Version|Changed By|Change Description|\n",
    "|-|-|-|-|\n",
    "|2023-05-26|0.1|Ramesh Sannareddy|Initial Version Created|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright © 2023 IBM Corporation. All rights reserved.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "conda-env-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
